import sqlite3
import pandas as pd
import re
from pathlib import Path
from tkinter.filedialog import askopenfilenames
from tkinter import Tk, messagebox
import os

# === Fahrermatching-Funktionen ===
def lade_fahrerliste():
    """L√§dt die Fahrerliste aus der Hauptdatenbank"""
    try:
        conn = sqlite3.connect("database.db")
        df = pd.read_sql_query("SELECT first_name, last_name FROM drivers", conn)
        conn.close()
        return df.apply(lambda row: f"{row['first_name']} {row['last_name']}", axis=1).tolist()
    except Exception as e:
        print(f"‚ö†Ô∏è Fehler beim Laden der Fahrerliste: {e}")
        return []

def match_name(import_name, fahrerliste):
    """F√ºhrt Fahrermatching durch"""
    if not fahrerliste:
        return ""
    
    tokens = [t.strip().lower() for t in re.split(r"[ ,]+", str(import_name)) if t.strip()]
    best_match = ""
    best_score = 0
    
    for fahrer in fahrerliste:
        fahrer_tokens = [t.strip().lower() for t in fahrer.split() if t.strip()]
        matches = sum(1 for t in tokens if t in fahrer_tokens)
        if matches > best_score:
            best_score = matches
            best_match = fahrer
    
    if best_score >= 2 and len(tokens) >= 2:
        return best_match
    else:
        return ""

def erkenne_plattform_aus_spalten(df):
    """Erkennt die Plattform basierend auf den vorhandenen Spalten"""
    spalten = [col.lower().strip() for col in df.columns]
    
    # Uber-Erkennung
    uber_indikatoren = [
        "vorname des fahrers", "nachname des fahrers", "gesamtums√§tze",
        "ums√§tze/std", "eingenommenes bargeld", "stunden online",
        "stunden fahrtzeit", "unternommene fahrten", "annahmerate"
    ]
    uber_score = sum(1 for ind in uber_indikatoren if any(ind in spalte for spalte in spalten))
    
    # Bolt-Erkennung
    bolt_indikatoren = [
        "driver", "gross earnings", "net earnings", "rider tips",
        "collected cash", "gross earnings per hour", "net earnings per hour"
    ]
    bolt_score = sum(1 for ind in bolt_indikatoren if any(ind in spalte for spalte in spalten))
    
    # 40100/Taxi-Erkennung
    taxi_indikatoren = [
        "fahrzeug", "fahrer", "fahrername", "abschluss", "buchungsart",
        "zahlungsmittel", "belegtext", "fahrtkosten", "trinkgeld", "umsatz",
        "bargeld", "auftragsart", "status"
    ]
    taxi_score = sum(1 for ind in taxi_indikatoren if any(ind in spalte for spalte in spalten))
    
    # Beste √úbereinstimmung finden
    scores = {
        "uber": uber_score,
        "bolt": bolt_score,
        "40100": taxi_score
    }
    
    best_platform = max(scores, key=scores.get)
    best_score = scores[best_platform]
    
    # Mindestens 3 Spalten m√ºssen √ºbereinstimmen
    if best_score >= 3:
        return best_platform
    else:
        return None

def extrahiere_kalenderwoche(filename):
    """Extrahiert die Kalenderwoche aus dem Dateinamen"""
    # Verschiedene Formate unterst√ºtzen
    patterns = [
        r"kw(\d+)",           # kw23
        r"woche(\d+)",        # woche23
        r"week(\d+)",         # week23
        r"(\d{2})",           # 23 (alleinstehend)
    ]
    
    for pattern in patterns:
        match = re.search(pattern, filename.lower())
        if match:
            return match.group(1)
    
    return None

def verarbeite_uber_daten(df, kalenderwoche):
    """Verarbeitet Uber-Daten"""
    print("üîç Erkenne Uber-Format...")
    
    # Spalten-Mapping
    spalten_mapping = {
        "Vorname des Fahrers": "first_name",
        "Nachname des Fahrers": "last_name",
        "Gesamtums√§tze": "gross_total",
        "Ums√§tze/Std": "gross_per_hour",
        "Eingenommenes Bargeld": "cash_collected",
        "Stunden online": "hours_online",
        "Stunden Fahrtzeit": "drive_time",
        "Unternommene Fahrten": "total_trips",
        "Annahmerate": "acceptance_rate"
    }
    
    # Verf√ºgbare Spalten umbenennen
    for alt, neu in spalten_mapping.items():
        if alt in df.columns:
            df.rename(columns={alt: neu}, inplace=True)
    
    # Zielspalten definieren
    zielspalten = [
        "first_name", "last_name", "gross_total", "gross_per_hour",
        "cash_collected", "hours_online", "drive_time",
        "total_trips", "acceptance_rate"
    ]
    
    # Nur vorhandene Spalten behalten
    df = df[[col for col in zielspalten if col in df.columns]].copy()
    
    # Fahrermatching (nur f√ºr interne Verarbeitung, nicht f√ºr DB)
    fahrerliste = lade_fahrerliste()
    if "first_name" in df.columns and "last_name" in df.columns:
        df["import_name"] = df["first_name"].fillna("") + " " + df["last_name"].fillna("")
        matched_names = df["import_name"].apply(lambda n: match_name(n, fahrerliste))
        print(f"   Fahrermatching: {len(matched_names[matched_names != ''])} von {len(df)} Fahrern gematcht")
        df.drop(columns=["import_name"], inplace=True)
    
    df["week"] = kalenderwoche
    return df, "uber.sqlite"

def verarbeite_bolt_daten(df, kalenderwoche):
    """Verarbeitet Bolt-Daten"""
    print("üîç Erkenne Bolt-Format...")
    
    # Spalten-Mapping
    spalten_mapping = {
        "Driver": "driver_name",
        "Gross earnings (total)|‚Ç¨": "gross_total",
        "Net earnings|‚Ç¨": "net_earnings",
        "Gross earnings per hour|‚Ç¨/h": "gross_per_hour",
        "Net earnings per hour|‚Ç¨/h": "net_per_hour",
        "Rider tips|‚Ç¨": "rider_tips",
        "Collected cash|‚Ç¨": "cash_collected"
    }
    
    # Verf√ºgbare Spalten umbenennen
    for alt, neu in spalten_mapping.items():
        if alt in df.columns:
            df.rename(columns={alt: neu}, inplace=True)
    
    # Zielspalten definieren
    zielspalten = [
        "driver_name", "gross_total", "net_earnings",
        "gross_per_hour", "net_per_hour", "rider_tips", "cash_collected"
    ]
    
    # Nur vorhandene Spalten behalten
    df = df[[col for col in zielspalten if col in df.columns]].copy()
    
    # Fahrermatching (nur f√ºr interne Verarbeitung, nicht f√ºr DB)
    fahrerliste = lade_fahrerliste()
    if "driver_name" in df.columns:
        matched_names = df["driver_name"].apply(lambda n: match_name(n, fahrerliste))
        print(f"   Fahrermatching: {len(matched_names[matched_names != ''])} von {len(df)} Fahrern gematcht")
    
    df["week"] = kalenderwoche
    return df, "bolt.sqlite"

def verarbeite_40100_daten(df, kalenderwoche):
    """Verarbeitet 40100/Taxi-Daten"""
    print("üîç Erkenne 40100/Taxi-Format...")
    
    # Zielspalten definieren
    zielspalten = [
        "Fahrzeug", "Fahrer", "Fahrername", "Abschluss", "Buchungsart",
        "Zahlungsmittel", "Belegtext", "Fahrtkosten", "Trinkgeld", "Umsatz",
        "Bargeld", "Auftragsart", "Status"
    ]
    
    # Nur vorhandene Spalten behalten
    df = df[[col for col in zielspalten if col in df.columns]].copy()
    
    # Numerische Spalten bereinigen
    for col in ["Fahrtkosten", "Trinkgeld", "Umsatz", "Bargeld"]:
        if col in df.columns:
            df[col] = (
                df[col].astype(str)
                .str.replace(",", ".")
                .str.replace(" ", "")
                .replace("nan", None)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")
    
    df["week"] = kalenderwoche
    return df, "40100.sqlite"

def erstelle_tabelle(conn, platform, tabelle):
    """Erstellt die entsprechende Tabelle"""
    create_sql = {
        "uber": f"""
            CREATE TABLE IF NOT EXISTS {tabelle} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                first_name TEXT,
                last_name TEXT,
                gross_total REAL,
                gross_per_hour REAL,
                cash_collected REAL,
                hours_online REAL,
                drive_time REAL,
                total_trips INTEGER,
                acceptance_rate REAL,
                week TEXT
            );
        """,
        "bolt": f"""
            CREATE TABLE IF NOT EXISTS {tabelle} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                driver_name TEXT,
                gross_total REAL,
                net_earnings REAL,
                gross_per_hour REAL,
                net_per_hour REAL,
                rider_tips REAL,
                cash_collected REAL,
                week TEXT
            );
        """,
        "40100": f"""
            CREATE TABLE IF NOT EXISTS {tabelle} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                Fahrzeug TEXT,
                Fahrer TEXT,
                Fahrername TEXT,
                Abschluss TEXT,
                Buchungsart TEXT,
                Zahlungsmittel TEXT,
                Belegtext TEXT,
                Fahrtkosten REAL,
                Trinkgeld REAL,
                Umsatz REAL,
                Bargeld REAL,
                Auftragsart TEXT,
                Status TEXT,
                week TEXT
            );
        """,
    }
    
    cursor = conn.cursor()
    cursor.execute(create_sql[platform])

def verarbeite_datei(csv_datei):
    """Hauptfunktion zur Dateiverarbeitung"""
    filename = Path(csv_datei).name
    print(f"\nüìÅ Verarbeite: {filename}")
    
    # Kalenderwoche extrahieren
    kw = extrahiere_kalenderwoche(filename)
    if not kw:
        print(f"‚ö†Ô∏è Keine Kalenderwoche im Dateinamen {filename} gefunden")
        return
    
    kalenderwoche = f"KW{kw}"
    tabelle = f"report_KW{kw}"
    
    # Trennzeichen erkennen
    try:
        with open(csv_datei, "r", encoding="utf-8") as f:
            header = f.readline()
            sep = ";" if header.count(";") > header.count(",") else ","
    except UnicodeDecodeError:
        # Fallback f√ºr andere Kodierungen
        with open(csv_datei, "r", encoding="latin-1") as f:
            header = f.readline()
            sep = ";" if header.count(";") > header.count(",") else ","
    
    # CSV laden
    try:
        df = pd.read_csv(csv_datei, sep=sep, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(csv_datei, sep=sep, encoding="latin-1")
    
    df.columns = df.columns.str.strip()
    
    # Plattform erkennen
    platform = erkenne_plattform_aus_spalten(df)
    if not platform:
        print(f"‚ö†Ô∏è Plattform f√ºr {filename} nicht erkannt")
        print(f"   Verf√ºgbare Spalten: {list(df.columns)}")
        return
    
    print(f"‚úÖ Plattform erkannt: {platform}")
    
    # Daten verarbeiten
    if platform == "uber":
        df, db_name = verarbeite_uber_daten(df, kalenderwoche)
    elif platform == "bolt":
        df, db_name = verarbeite_bolt_daten(df, kalenderwoche)
    elif platform == "40100":
        df, db_name = verarbeite_40100_daten(df, kalenderwoche)
    
    # In Datenbank speichern
    try:
        conn = sqlite3.connect(db_name)
        erstelle_tabelle(conn, platform, tabelle)
        
        # Duplikate pr√ºfen
        if platform == "uber":
            check_sql = f"SELECT first_name, last_name FROM {tabelle} WHERE week = ?"
            merge_cols = ["first_name", "last_name"]
        elif platform == "bolt":
            check_sql = f"SELECT driver_name FROM {tabelle} WHERE week = ?"
            merge_cols = ["driver_name"]
        elif platform == "40100":
            check_sql = f"SELECT Fahrername, Abschluss FROM {tabelle} WHERE week = ?"
            merge_cols = ["Fahrername", "Abschluss"]
        
        try:
            existing = pd.read_sql_query(check_sql, conn, params=[kalenderwoche])
            if not existing.empty:
                df = df.merge(existing, on=merge_cols, how="left", indicator=True)
                df = df[df["_merge"] == "left_only"].drop(columns=["_merge"])
        except Exception as e:
            print(f"‚ö†Ô∏è Fehler bei Duplikatspr√ºfung: {e}")
        
        if not df.empty:
            df.to_sql(tabelle, conn, if_exists="append", index=False)
            print(f"‚úÖ {len(df)} Zeilen importiert: {filename} ‚Üí {db_name} ‚Üí {tabelle}")
        else:
            print(f"‚ÑπÔ∏è Keine neuen Daten importiert: {filename}")
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        print(f"‚ùå Fehler beim Speichern: {e}")

def main():
    """Hauptfunktion"""
    print("üöÄ Intelligenter CSV-Import gestartet")
    print("=" * 50)
    
    # Dateien ausw√§hlen
    Tk().withdraw()
    dateien = askopenfilenames(
        title="CSV-Dateien ausw√§hlen", 
        filetypes=[("CSV-Dateien", "*.csv"), ("Alle Dateien", "*.*")]
    )
    
    if not dateien:
        print("‚ùå Keine Dateien ausgew√§hlt.")
        return
    
    print(f"üìÅ {len(dateien)} Datei(en) ausgew√§hlt")
    
    # Dateien verarbeiten
    for datei in dateien:
        try:
            verarbeite_datei(datei)
        except Exception as e:
            print(f"‚ùå Fehler bei {Path(datei).name}: {e}")
    
    print("\n‚úÖ Import abgeschlossen!")

if __name__ == "__main__":
    main() 